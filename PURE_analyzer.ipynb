{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_path = \"data\\\\Pure_Annotate_Dataset.csv\"\n",
    "pure_test_data_path = \"data\\\\testData.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqlist_path = os.path.join(\"data\", \"ReqList_ReqNet_ReqSim\", \"1.1 ReqLists\")\n",
    "req_list_files = os.listdir(reqlist_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#req_path = os.path.join(\"data\", \"req\")\n",
    "req_path = os.path.join(\"data\", \"ReqList_ReqNet_ReqSim\", \"0    Requirement Specification Documents\")\n",
    "req_doc_files = os.listdir(req_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_structure_path = os.path.join(\"data\", \"ReqList_ReqNet_ReqSim\", \"1.3 DocumentStructure - Metadata\")\n",
    "doc_structure = os.listdir(doc_structure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de arquivos de requisitos em req_list_files: 86\n",
      "Número de documentos de requisitos em rec_doc_files: 82\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Número de arquivos de requisitos em req_list_files: {len(req_list_files)}\")\n",
    "print(f\"Número de documentos de requisitos em rec_doc_files: {len(req_doc_files)}\")\n",
    "print(len(doc_structure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2014 - Minutia', '2002 - evla back', '2017 - NISTMfgData', '2007 - puget sound', '2004 - grid bgc', '2019 - MOSAR', '2006 - eirene sys 15', '2017 - ePhyto', '2004 - colorcast', '2010 - blit draft', '2000 - Barrel', '2018 - DataWarehouse', '2001 - esa', '2005 - znix', '2005 - triangle', 'light-control-system', '2001 - elsfork', 'RROWDyS', '1997 - Modis', '2005 - grid 3D', '2009 - warc III', '2005 - phin', '2009 - library2', '2001 - npac', '2011 - CCHIT', '1995 - Landsat7', '2008 - caiso', '2007 - e-store', '2022 - UAM IMS', '1998 - themas', '2003 - tachonet', '2007 - ertms', '2022 - MobileSurveillance', '2009 - gaia', '2001 - hats', '0000 - inventory', '2009 - video search', 'automated-insulin-pump', '2013 - iTrust', '2009 - library', '2000 - nasa x38', '2005 - clarus high', '1999 - Defense', '1995 - gemini', '2012 - NASAProcessReq', '2003 - agentmom', '2008 - virtual ed', '0000 - cctns', '2007 - get real 0', '2005 - clarus low', '2009 - peppol', 'EHR System FuncReq - LA DHS', '2007 - mdot', '2007 - nde', '2010 - mashboot', '2005 - nenios', '1999 - multi-mahjong', '1999 - tcs', '2004 - rlcs', '2016 - FDP Clearinghouse', '2004 - sprat', '2005 - pontis', '2010 - home 1', '2010 - split merge', '2010 - fishing', '2001 - beyond', '2003 - pnnl', '0000 - gamma j', '2004 - SGVTraffic', '2007 - Wildlife', '2007 - eirene fun 7', 'EHR System TechReq LA DHS', '2021 - ReqView', '2002 - evla corr', '2003 - qheadache', '2006 - stewards', '2011 - KMS', '2001 - ctc network'}\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "doc_struct_names = set([x[:x.find(\".\")] for x in doc_structure])\n",
    "req_doc_files_names = set([x[:x.find(\".\")] for x in req_doc_files])\n",
    "    \n",
    "inter_list_doc = set(doc_struct_names).intersection(set(req_doc_files_names))\n",
    "print(inter_list_doc)\n",
    "print(len(inter_list_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos em doc_struct_names que não estão em req_doc_files_names: ['2012 - EMR CCHCS EA', '2012 - EMR CCHCS ISO', '2012 - EMR CCHIT LT', '2012 - EMR HHS', '2012 - EMR HL7 DC', '2012 - EMR HL7 IN', '2012 - EMR Pharmacy', '2021 - Connected Vehicle Pilot NYC']\n",
      "Arquivos em req_doc_files_names que não estão em doc_struct_names: ['2012 - EMR CCHCS EA ISO HL7 IN', '2012 - EMR HL7 DC - CCHIT LT - Pharmacy - HHS', '2021 - ConnectedVehiclePilotNYC']\n"
     ]
    }
   ],
   "source": [
    "A = list(doc_struct_names - req_doc_files_names)\n",
    "B = list(req_doc_files_names - doc_struct_names)\n",
    "A.sort()\n",
    "B.sort() \n",
    "print(f\"Arquivos em doc_struct_names que não estão em req_doc_files_names: {A}\")\n",
    "print(f\"Arquivos em req_doc_files_names que não estão em doc_struct_names: {B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2012 - EMR CCHCS EA ISO HL7 IN\n",
      "2012 - EMR HL7 DC - CCHIT LT - Pharmacy - HHS\n",
      "2021 - ConnectedVehiclePilotNYC\n"
     ]
    }
   ],
   "source": [
    "print(len(B))\n",
    "for file in B:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "2012 - EMR CCHCS EA\n",
      "2012 - EMR CCHCS ISO\n",
      "2012 - EMR CCHIT LT\n",
      "2012 - EMR HHS\n",
      "2012 - EMR HL7 DC\n",
      "2012 - EMR HL7 IN\n",
      "2012 - EMR Pharmacy\n",
      "2021 - Connected Vehicle Pilot NYC\n"
     ]
    }
   ],
   "source": [
    "print(len(A))\n",
    "for file in A:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2014 - Minutia', '2002 - evla back', '2017 - NISTMfgData', '2007 - puget sound', '2004 - grid bgc', '2019 - MOSAR', '2006 - eirene sys 15', '2017 - ePhyto', '2004 - colorcast', '2010 - blit draft', '2000 - Barrel', '2018 - DataWarehouse', '2001 - esa', '2005 - znix', '2005 - triangle', '2021 - ConnectedVehiclePilotNYC', 'light-control-system', '2001 - elsfork', 'RROWDyS', '1997 - Modis', '2005 - grid 3D', '2009 - warc III', '2005 - phin', '2009 - library2', '2001 - npac', '2011 - CCHIT', '1995 - Landsat7', '2008 - caiso', '2007 - e-store', '2022 - UAM IMS', '1998 - themas', '2003 - tachonet', '2007 - ertms', '2022 - MobileSurveillance', '2009 - gaia', '2001 - hats', '0000 - inventory', '2009 - video search', 'automated-insulin-pump', '2013 - iTrust', '2009 - library', '2000 - nasa x38', '2005 - clarus high', '1999 - Defense', '1995 - gemini', '2012 - NASAProcessReq', '2003 - agentmom', '2008 - virtual ed', '0000 - cctns', '2007 - get real 0', '2005 - clarus low', '2009 - peppol', 'EHR System FuncReq - LA DHS', '2007 - mdot', '2007 - nde', '2010 - mashboot', '2005 - nenios', '1999 - multi-mahjong', '1999 - tcs', '2004 - rlcs', '2016 - FDP Clearinghouse', '2004 - sprat', '2005 - pontis', '2010 - home 1', '2010 - split merge', '2010 - fishing', '2001 - beyond', '2003 - pnnl', '0000 - gamma j', '2004 - SGVTraffic', '2007 - Wildlife', '2007 - eirene fun 7', 'EHR System TechReq LA DHS', '2021 - ReqView', '2002 - evla corr', '2003 - qheadache', '2006 - stewards', '2011 - KMS', '2001 - ctc network'}\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "req_list_files_names = set([x[:x.find(\".\")] for x in req_list_files])\n",
    "req_doc_files_names = set([x[:x.find(\".\")] for x in req_doc_files])\n",
    "    \n",
    "inter_list_doc = set(req_list_files_names).intersection(set(req_doc_files_names))\n",
    "print(inter_list_doc)\n",
    "print(len(inter_list_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos em req_list_files_names que não estão em req_doc_files_names: ['2012 - EMR CCHCS EA', '2012 - EMR CCHCS ISO', '2012 - EMR CCHIT LT', '2012 - EMR HHS', '2012 - EMR HL7 DC', '2012 - EMR HL7 IN', '2012 - EMR Pharmacy']\n",
      "Arquivos em req_doc_files_names que não estão em req_list_files_names: ['2012 - EMR CCHCS EA ISO HL7 IN', '2012 - EMR HL7 DC - CCHIT LT - Pharmacy - HHS']\n"
     ]
    }
   ],
   "source": [
    "req_files_list_sub_doc = list(req_list_files_names - req_doc_files_names)\n",
    "req_files_doc_sub_list = list(req_doc_files_names - req_list_files_names)\n",
    "req_files_list_sub_doc.sort()\n",
    "req_files_doc_sub_list.sort() \n",
    "print(f\"Arquivos em req_list_files_names que não estão em req_doc_files_names: {req_files_list_sub_doc}\")\n",
    "print(f\"Arquivos em req_doc_files_names que não estão em req_list_files_names: {req_files_doc_sub_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2012 - EMR CCHCS EA ISO HL7 IN\n",
      "2012 - EMR HL7 DC - CCHIT LT - Pharmacy - HHS\n"
     ]
    }
   ],
   "source": [
    "print(len(req_files_doc_sub_list))\n",
    "for file in req_files_doc_sub_list:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "2012 - EMR CCHCS EA\n",
      "2012 - EMR CCHCS ISO\n",
      "2012 - EMR CCHIT LT\n",
      "2012 - EMR HHS\n",
      "2012 - EMR HL7 DC\n",
      "2012 - EMR HL7 IN\n",
      "2012 - EMR Pharmacy\n"
     ]
    }
   ],
   "source": [
    "print(len(req_files_list_sub_doc))\n",
    "for file in req_files_list_sub_doc:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_req = {\n",
    "        \"2012 - EMR CCHCS EA ISO HL7 IN 20120420_Attach8\" : [\"2012 - EMR CCHCS EA\", \"2012 - EMR CCHCS ISO\", \"2012 - EMR HL7 IN\"],\n",
    "        \"2012 - EMR HL7 DC - CCHIT LT - Pharmacy - HHS_Attach9\" : [\"2012 - EMR CCHIT LT\", \"2012 - EMR HHS\", \"2012 - EMR HL7 DC\", \"2012 - EMR Pharmacy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from PyPDF2 import PdfReader, PdfWriter\\n\\ncaminho_pdf_original = \"Software_Requirements_3rd_Edition.pdf\"\\ncaminho_pdf_saida = \"Understanding_user_requirements.pdf\"\\n\\n\\nreader = PdfReader(caminho_pdf_original)\\nwriter = PdfWriter()\\n\\n\\nfor i in range(175, 199):  \\n    writer.add_page(reader.pages[i])\\n\\nwith open(caminho_pdf_saida, \"wb\") as f:\\n    writer.write(f)\\n\\nprint(\"PDF gerado com sucesso!\")'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "caminho_pdf_original = \"Software_Requirements_3rd_Edition.pdf\"\n",
    "caminho_pdf_saida = \"Understanding_user_requirements.pdf\"\n",
    "\n",
    "\n",
    "reader = PdfReader(caminho_pdf_original)\n",
    "writer = PdfWriter()\n",
    "\n",
    "\n",
    "for i in range(175, 199):  \n",
    "    writer.add_page(reader.pages[i])\n",
    "\n",
    "with open(caminho_pdf_saida, \"wb\") as f:\n",
    "    writer.write(f)\n",
    "\n",
    "print(\"PDF gerado com sucesso!\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list_req_path = \"data/ReqList_ReqNet_ReqSim/1.2 all_reqlists.csv\"\n",
    "df_all_list_req = pd.read_csv(all_list_req_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segundos: 38103\n",
      "Minutos: 1143.09\n",
      "Horas: 19.0515\n",
      "Dias: 0.7938125\n"
     ]
    }
   ],
   "source": [
    "print(f\"Segundos: {df_all_list_req.size}\")\n",
    "print(f\"Minutos: {(df_all_list_req.size*3)/100}\")\n",
    "print(f\"Horas: {(df_all_list_req.size*3)/60/100}\")\n",
    "print(f\"Dias: {(df_all_list_req.size*3)/60/100/24}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = df_all_list_req[\"requirement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = df_all_list_req[\"keys\"]\n",
    "\n",
    "keys_0 = []\n",
    "keys_1 = []\n",
    "keys_2 = []\n",
    "keys_list = [keys_1, keys_2]\n",
    "\n",
    "for key in keys:\n",
    "    key_0 = \".\".join(key.split(\".\")[:2])\n",
    "    key_rest = key.split(\".\")[2:]\n",
    "    for i in range(2):\n",
    "        try:\n",
    "            keys_list[i].append(key_rest[i])\n",
    "        except:\n",
    "            keys_list[i].append(\"\")\n",
    "    keys_0.append(key_0)\n",
    "df_all_list_req[\"keys_0\"] = keys_0\n",
    "df_all_list_req[\"keys_1\"] = keys_1\n",
    "df_all_list_req[\"keys_2\"] = keys_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_subkeys(key):\n",
    "    key_split = key.split(\".\")\n",
    "    key_0 = key_split[0]\n",
    "    key_1 = key_split[1]\n",
    "    key_2 = \".\".join(key_split[2:])\n",
    "\n",
    "    return key_0, key_1, key_2\n",
    "\n",
    "k0, k1, k2 = extract_subkeys(\"CA2.3.4\")\n",
    "print(k0)\n",
    "print(k1)\n",
    "print(k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m reqs_parsed \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m req \u001b[38;5;129;01min\u001b[39;00m requirements:\n\u001b[1;32m----> 7\u001b[0m     req_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     reqs_parsed\u001b[38;5;241m.\u001b[39mappend(req_parsed)\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\pipeline\\tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[0;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[1;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[0;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\thinc\\layers\\maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     50\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[1;32m---> 52\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[0;32m     54\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "reqs_parsed = []\n",
    "\n",
    "for req in requirements:\n",
    "    req_parsed = nlp(req)\n",
    "    reqs_parsed.append(req_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_list_req[\"parsed\"] = reqs_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = [] # Verbo (should provide, enable, etc.)\n",
    "aux = [] # Auxiliar (should, must, can, is, are, etc.)\n",
    "noun = [] # Substantivo (system, user, report, etc.)\n",
    "propn = [] # Substantivo próprio (Nome da empresa, nome de funcionário, etc.)\n",
    "pron = [] # Pronome (user, it, they, he, she, etc.)\n",
    "adj = [] # Adjetivo (detailed, new, old, etc.)\n",
    "adv = [] # Advérbio (automatically, only, quickly, slowly, etc.)\n",
    "sconj = [] # Conjunção subordinada (so, that, when, if, because, etc.)\n",
    "part = [] # Particípio (to provide, to allow, should be, should have, etc.)\n",
    "org = [] # Organização (Nome da empresa, nome de funcionário, etc.)\n",
    "\n",
    "for req in reqs_parsed:\n",
    "    verb.append([token for token in req if token.pos_ == \"VERB\"])\n",
    "    aux.append([token for token in req if token.pos_ == \"AUX\"])\n",
    "    noun.append([token for token in req if token.pos_ == \"NOUN\"])\n",
    "    propn.append([token for token in req if token.pos_ == \"PROPN\"])\n",
    "    pron.append([token for token in req if token.pos_ == \"PRON\"])\n",
    "    adj.append([token for token in req if token.pos_ == \"ADJ\"])\n",
    "    adv.append([token for token in req if token.pos_ == \"ADV\"])\n",
    "    sconj.append([token for token in req if token.pos_ == \"SCONJ\"])\n",
    "    part.append([token for token in req if token.pos_ == \"PART\"])\n",
    "    org.append([token for token in req if token.pos_ == \"ORG\"])\n",
    "        \n",
    "df_all_list_req[\"verb\"] = verb\n",
    "df_all_list_req[\"aux\"] = aux\n",
    "df_all_list_req[\"noun\"] = noun\n",
    "df_all_list_req[\"propn\"] = propn\n",
    "df_all_list_req[\"pron\"] = pron\n",
    "df_all_list_req[\"adj\"] = adj\n",
    "df_all_list_req[\"adv\"] = adv\n",
    "df_all_list_req[\"sconj\"] = sconj\n",
    "df_all_list_req[\"part\"] = part\n",
    "df_all_list_req[\"org\"] = org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution should provide detailed context-sensitive help material for all the possible actions and scenarios on all user interfaces in the application.\n",
      "The help should be accessible to the users both in the offline and online mode.\n",
      "The solution should provide an interface for the user to log any defects or enhancement requests on the application and track thereafter.\n",
      "The solution should send alerts (e.g., email, SMS) to the user if the user chooses to whenever any action has been taken on the alert\n",
      "The solution should enable the user to track the submitted defect or enhancement request.\n",
      "The solution should enable the help-desk user to view the reports on the submitted defects or enhancement requests category- wise, status-wise, and age-wise.\n",
      "The support solution should be accessible to the users both from within the application and also outside the application through a browser interface.\n",
      "The System must keep an unalterable audit trail capable of automatically capturing and storing information about all the actions (create/read/update/delete) that are taken upon the critical entities (case, suspect, property, …) in the system\n",
      "The System must keep an unalterable audit trail capable of automatically capturing and storing information about the user initiating and or carrying out the action;\n",
      "The System must keep an unalterable audit trail capable of automatically capturing and storing information about the date and time of the event.\n",
      "The System must keep an unalterable audit trail capable of automatically capturing and storing information about administrative parameters\n",
      "Once the audit trail functionality has been activated, the System must track events without manual intervention, and store in the audit trail information about them.\n",
      "The System must maintain the audit trail for as long as required, which will be at least for the life of the case to which it refers.\n",
      "The System must ensure that audit trail data is available for inspection on request, so that a specific event can be identified and all related data made accessible, and that this can be achieved by authorised external personnel who have little or no familiarity with the system.\n",
      "The System must be able to export audit trails for specified cases (without affecting the audit trail stored by the System). This functionality can be used by external auditors who wish to examine or analyse system activity.\n",
      "The System must be able to capture and store violations (i.e. A user’s attempts to access a case to which he is denied access), and (where violations can validly be attempted) attempted violations, of access control mechanisms.\n",
      "The System must at a minimum be able to provide rep orts for actions on cases organised by case, user, and in chronological sequence.\n",
      "The System should be able to provide reports for actions on cases organised by workstation and (where technically appropriate) by network address.\n",
      "The System must allow the user to limit access to cases to specified users or user groups.\n",
      "The system should provide for role-based control for the functionality within the system.\n",
      "The System must allow a user to be a member of more than one group.\n",
      "The System must allow only admin-users to set up user profiles and allocate users to groups.\n",
      "The System should allow a user to stipulate which other users or groups can access cases.\n",
      "The System must allow changes to security attributes for groups or users (such as access rights, security level, privileges, password allocation and management) to be made only by super-user.\n",
      "If a user requests access to, or searches for, a case which he does not have the right to access, the System must provide one of the following responses (selectable at configuration time): • display title and metadata; • display the existence of a case but not its title or other metadata; • do not display any case information or indicate its existence in any way. These options are presented in order of increasing security.  Note that the requirement in the third option (i.e. the most stringent) implies that the System must not include such cases in any count of search results; this level of security is normally appropriate for cases dealing with matters such as national security.\n",
      "If a user performs a quick or advanced search, the System must never include in the search result list any record which the user does not have the right to access.\n",
      "If the System allows users to make unauthorised attempts to access cases, it must log these in the audit trail.\n",
      "Any access to cases, and all other activities involving the cases and related documents or data should also need to be stored in the audit trail to ensure legal admissibility and to assist in data recovery.\n",
      "All error messages produced by the System must be meaningful, so that they can be appropriately acted upon by the users who are likely to see them. Ideally, each error message will be accompanied by explanatory text and an indication of the action(s) which the user can take in response to the error.\n",
      "The System must employ a single set of user interface rules, or a small number of sets to provide a familiar and common look and feel for the application.\n"
     ]
    }
   ],
   "source": [
    "reqs = df_all_list_req[\"requirement\"]\n",
    "for req in reqs[:30]:\n",
    "    print(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['keys_3'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_all_list_req\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequirement\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeys\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeys_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeys_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeys_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m30\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['keys_3'] not in index\""
     ]
    }
   ],
   "source": [
    "df_all_list_req[[\"requirement\", \"keys\", \"keys_1\", \"keys_2\", \"keys_3\"]].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 16:31:44,798 | DEBUG | 3945911190:<module>:line28 - Starting the dataset preparation process\n",
      "2025-04-11 16:31:45,354 | DEBUG | 3945911190:<module>:line36 - Subkeys successfully extracted and added to DataFrame.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>keys</th>\n",
       "      <th>requirement</th>\n",
       "      <th>user story llama-4-maverick</th>\n",
       "      <th>user story llama-3-3-70b</th>\n",
       "      <th>keys_0</th>\n",
       "      <th>keys_1</th>\n",
       "      <th>keys_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000 - cctns.txt</td>\n",
       "      <td>G.D0.1.1</td>\n",
       "      <td>The solution should provide detailed context-s...</td>\n",
       "      <td>As a user of the application, I want to access...</td>\n",
       "      <td>As a user of the application, I want to have a...</td>\n",
       "      <td>G.D0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000 - cctns.txt</td>\n",
       "      <td>G.D0.1.2</td>\n",
       "      <td>The help should be accessible to the users bot...</td>\n",
       "      <td>As a user, I want to be able to access the hel...</td>\n",
       "      <td>As a user, I want to be able to access help re...</td>\n",
       "      <td>G.D0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000 - cctns.txt</td>\n",
       "      <td>G.D0.2.1</td>\n",
       "      <td>The solution should provide an interface for t...</td>\n",
       "      <td>Here is the user story based on the given requ...</td>\n",
       "      <td>As a user of the application, I want to be abl...</td>\n",
       "      <td>G.D0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000 - cctns.txt</td>\n",
       "      <td>G.D0.2.2</td>\n",
       "      <td>The solution should send alerts (e.g., email, ...</td>\n",
       "      <td>As a user, I want to receive notifications (e....</td>\n",
       "      <td>As a user, I want to receive alerts via email ...</td>\n",
       "      <td>G.D0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000 - cctns.txt</td>\n",
       "      <td>G.D0.2.3</td>\n",
       "      <td>The solution should enable the user to track t...</td>\n",
       "      <td>As a user, I want to be able to view the statu...</td>\n",
       "      <td>As a user, I want to be able to track the stat...</td>\n",
       "      <td>G.D0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename      keys  \\\n",
       "0  0000 - cctns.txt  G.D0.1.1   \n",
       "1  0000 - cctns.txt  G.D0.1.2   \n",
       "2  0000 - cctns.txt  G.D0.2.1   \n",
       "3  0000 - cctns.txt  G.D0.2.2   \n",
       "4  0000 - cctns.txt  G.D0.2.3   \n",
       "\n",
       "                                         requirement  \\\n",
       "0  The solution should provide detailed context-s...   \n",
       "1  The help should be accessible to the users bot...   \n",
       "2  The solution should provide an interface for t...   \n",
       "3  The solution should send alerts (e.g., email, ...   \n",
       "4  The solution should enable the user to track t...   \n",
       "\n",
       "                         user story llama-4-maverick  \\\n",
       "0  As a user of the application, I want to access...   \n",
       "1  As a user, I want to be able to access the hel...   \n",
       "2  Here is the user story based on the given requ...   \n",
       "3  As a user, I want to receive notifications (e....   \n",
       "4  As a user, I want to be able to view the statu...   \n",
       "\n",
       "                            user story llama-3-3-70b keys_0 keys_1 keys_2  \n",
       "0  As a user of the application, I want to have a...   G.D0      1      1  \n",
       "1  As a user, I want to be able to access help re...   G.D0      1      2  \n",
       "2  As a user of the application, I want to be abl...   G.D0      2      1  \n",
       "3  As a user, I want to receive alerts via email ...   G.D0      2      2  \n",
       "4  As a user, I want to be able to track the stat...   G.D0      2      3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "from src.logger import setup_logger\n",
    "\n",
    "logger = setup_logger()\n",
    "\n",
    "def extract_user_story_parts(text):\n",
    "    pattern = r\"As a (.*?), I want (.*?) so that (.*?)(?:\\.|$)\"\n",
    "    match = re.findall(pattern, text, re.IGNORECASE)[0]\n",
    "    result = {\n",
    "            \"type_of_user\": match[0],\n",
    "            \"goal\": match[1],\n",
    "            \"reason\": match[2]\n",
    "        }\n",
    "    return result\n",
    "\n",
    "def extract_subkeys(key):\n",
    "    key_split = key.split(\".\")\n",
    "    key_0 = \".\".join(key_split[:2])\n",
    "    key_1 = key_split[2]\n",
    "    key_2 = \".\".join(key_split[3:])\n",
    "\n",
    "    return key_0, key_1, key_2\n",
    "\n",
    "\n",
    "logger.debug(\"Starting the dataset preparation process\")\n",
    "pure_req_user_stories_path = os.path.join(\"data\", \"pure_req_user_stories.csv\")\n",
    "pure_req_us_df = pd.read_csv(pure_req_user_stories_path)\n",
    "pure_req_us_df.rename(columns={\"databricks-llama-4-maverick\": \"user story llama-4-maverick\", \"databricks-meta-llama-3-3-70b-instruct\": \"user story llama-3-3-70b\"}, inplace=True)\n",
    "pure_req_us_df[[\"keys_0\", \"keys_1\", \"keys_2\"]] = pure_req_us_df[\"keys\"].apply(\n",
    "        extract_subkeys\n",
    "    ).apply(pd.Series)\n",
    "\n",
    "logger.debug(\"Subkeys successfully extracted and added to DataFrame.\")\n",
    "pure_req_us_df.head()\n",
    "pure_req_us_df = pure_req_us_df[[\"requirement\", \"keys\", \"keys_0\", \"keys_1\", \"keys_2\", \"user story llama-4-maverick\", \"user story llama-3-3-70b\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
